{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786ba6d6",
   "metadata": {},
   "source": [
    "# Label-free CBM — Evaluation (Adapted, PVC Defaults)\n",
    "\n",
    "PVC-aware defaults for Nautilus:\n",
    "- `DATA_ROOT=/kayla/dataset`\n",
    "- `CKPT_PATH=/kayla/saved_models/cifar10_label_free/best.pt`\n",
    "- `CONCEPTS_TXT=/kayla/cbm_library/concepts/main/outputs/label_free/cifar10_filtered.txt`\n",
    "\n",
    "You can still override via environment variables.\n",
    "**Created:** 2025-08-15T22:26:27.448140Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup & imports ---\n",
    "import os, sys, json, math, random, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Repro\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# === PVC defaults (override with env if you like) ===\n",
    "DATA_ROOT = os.environ.get(\"DATA_ROOT\", \"/kayla/dataset\")\n",
    "CKPT_PATH = os.environ.get(\"CKPT_PATH\", \"/kayla/saved_models/cifar10_label_free/best.pt\")\n",
    "CONCEPTS_TXT = os.environ.get(\"CONCEPTS_TXT\", \"/kayla/cbm_library/concepts/main/outputs/label_free/cifar10_filtered.txt\")\n",
    "\n",
    "BATCH_SIZE = int(os.environ.get(\"EVAL_BATCH\", 64))\n",
    "NUM_WORKERS = int(os.environ.get(\"EVAL_WORKERS\", 2))\n",
    "TOPK = (1, 5)\n",
    "TOP_CONTRIB = int(os.environ.get(\"TOP_CONTRIB\", 10))\n",
    "\n",
    "EVAL_SPLIT = os.environ.get(\"EVAL_SPLIT\", \"test\")  # 'test' or 'train'\n",
    "\n",
    "print(\"Paths:\")\n",
    "print(\"  DATA_ROOT  =\", DATA_ROOT)\n",
    "print(\"  CKPT_PATH  =\", CKPT_PATH)\n",
    "print(\"  CONCEPTS   =\", CONCEPTS_TXT)\n",
    "print(\"Eval opts: BATCH_SIZE =\", BATCH_SIZE, \" WORKERS =\", NUM_WORKERS, \" TOPK =\", TOPK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data loading (CIFAR-10 by default) ---\n",
    "def build_cifar10(root, train=False):\n",
    "    tfm = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return torchvision.datasets.CIFAR10(root=root, train=train, download=True, transform=tfm)\n",
    "\n",
    "eval_is_train = EVAL_SPLIT.lower().startswith(\"train\")\n",
    "ds = build_cifar10(DATA_ROOT, train=eval_is_train)\n",
    "dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
    "CLASS_NAMES = ds.classes\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(f\"Dataset: CIFAR-10 | split={EVAL_SPLIT} | size={len(ds)} | classes={NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utilities: accuracy & plotting ---\n",
    "def topk_accuracy(logits: torch.Tensor, targets: torch.Tensor, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = targets.size(0)\n",
    "    _, pred = logits.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(targets.view(1, -1).expand_as(pred))\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(float(correct_k.mul_(100.0 / batch_size)))\n",
    "    return res\n",
    "\n",
    "def barplot_contributions(concept_names: List[str], contrib: np.ndarray, title=\"Top concept contributions\", top_n=10):\n",
    "    idx = np.argsort(-np.abs(contrib))[:top_n]\n",
    "    names = [concept_names[i] if i < len(concept_names) else f\"c{i}\" for i in idx]\n",
    "    vals = contrib[idx]\n",
    "    plt.figure(figsize=(8, max(3, top_n * 0.35)))\n",
    "    y = np.arange(len(idx))\n",
    "    plt.barh(y, vals)\n",
    "    plt.yticks(y, names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"signed contribution (w_i * c_i)\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model loading for both original LF-CBM & cbm_library ---\n",
    "def load_checkpoint_any(path: str):\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    W_c = None; W_y = None; concept_names = []\n",
    "\n",
    "    if isinstance(ckpt, dict):\n",
    "        # Direct keys\n",
    "        W_c = ckpt.get(\"W_c\", W_c)\n",
    "        W_y = ckpt.get(\"W_y\", W_y)\n",
    "        concept_names = ckpt.get(\"concept_names\", concept_names)\n",
    "\n",
    "        # Nested common patterns\n",
    "        if W_c is None or W_y is None:\n",
    "            st = ckpt.get(\"state_dict\") or ckpt.get(\"model\") or {}\n",
    "            if isinstance(st, dict):\n",
    "                W_c = st.get(\"concept_layer.weight\", W_c)\n",
    "                W_y = st.get(\"final_layer.weight\", W_y)\n",
    "\n",
    "    # Numpy -> torch\n",
    "    if W_c is not None and not isinstance(W_c, torch.Tensor):\n",
    "        import numpy as _np\n",
    "        if isinstance(W_c, _np.ndarray):\n",
    "            W_c = torch.tensor(W_c, dtype=torch.float32)\n",
    "    if W_y is not None and not isinstance(W_y, torch.Tensor):\n",
    "        import numpy as _np\n",
    "        if isinstance(W_y, _np.ndarray):\n",
    "            W_y = torch.tensor(W_y, dtype=torch.float32)\n",
    "\n",
    "    if W_c is None or W_y is None:\n",
    "        raise RuntimeError(\"Checkpoint missing W_c and/or W_y. Expected original LF-CBM or compatible cbm_library save.\")\n",
    "\n",
    "    W_c = W_c.float().contiguous()\n",
    "    W_y = W_y.float().contiguous()\n",
    "    print(\"Loaded shapes: W_c =\", tuple(W_c.shape), \" W_y =\", tuple(W_y.shape))\n",
    "    return W_c, W_y, concept_names, ckpt\n",
    "\n",
    "try:\n",
    "    W_c, W_y, CONCEPT_NAMES, CKPT_META = load_checkpoint_any(CKPT_PATH)\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Failed to load checkpoint:\", e)\n",
    "    print(\"Using small random demo weights so you can run the notebook structure (not for real eval).\")\n",
    "    W_c = torch.randn(100, 512) * 0.01\n",
    "    W_y = torch.randn(NUM_CLASSES, 100) * 0.01\n",
    "    CONCEPT_NAMES = [f\"concept_{i}\" for i in range(W_c.size(0))]\n",
    "    CKPT_META = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature extractor (ResNet-18 default) ---\n",
    "from torchvision import models\n",
    "def build_backbone():\n",
    "    m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    m.fc = nn.Identity()\n",
    "    return m.to(DEVICE).eval()\n",
    "\n",
    "backbone = build_backbone()\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(dataloader):\n",
    "    feats = []\n",
    "    for x, _ in dataloader:\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        f = backbone(x)\n",
    "        if f.ndim > 2:\n",
    "            f = torch.flatten(f, 1)\n",
    "        feats.append(f.detach().cpu())\n",
    "    return torch.cat(feats, dim=0)\n",
    "\n",
    "print(\"Extracting features...\")\n",
    "X = extract_features(dl)  # [N, D]\n",
    "ys = torch.tensor([y for _, y in ds], dtype=torch.long)\n",
    "print(\"Feature matrix:\", tuple(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Forward & metrics ---\n",
    "@torch.no_grad()\n",
    "def forward_logits(X_cpu: torch.Tensor, W_c: torch.Tensor, W_y: torch.Tensor):\n",
    "    C = X_cpu @ W_c.t()   # [N, C]\n",
    "    Y = C @ W_y.t()       # [N, K]\n",
    "    return C, Y\n",
    "\n",
    "C_acts, logits = forward_logits(X, W_c, W_y)\n",
    "\n",
    "top1, top5 = topk_accuracy(logits, ys, topk=(1,5))\n",
    "print(f\"Top-1: {top1:.2f}%   Top-5: {top5:.2f}%\")\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(ys.numpy(), logits.argmax(dim=1).numpy(), labels=list(range(NUM_CLASSES)))\n",
    "    print(\"Confusion matrix shape:\", cm.shape)\n",
    "except Exception as e:\n",
    "    print(\"sklearn not available for confusion matrix:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a75370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sparsity & concept usage ---\n",
    "import numpy as np\n",
    "Wy = W_y.cpu().numpy()\n",
    "abs_Wy = np.abs(Wy)\n",
    "\n",
    "per_class_nnz = (abs_Wy > 1e-12).sum(axis=1)\n",
    "global_nnz = (abs_Wy > 1e-12).any(axis=0).sum()\n",
    "\n",
    "print(\"Per-class nonzero concepts:\", per_class_nnz.tolist())\n",
    "print(\"Mean nonzeros per class:\", float(np.mean(per_class_nnz)))\n",
    "print(\"Global #effective concepts:\", int(global_nnz), \"/\", Wy.shape[1])\n",
    "\n",
    "def top_concepts_for_class(k=10, class_idx=0):\n",
    "    w = Wy[class_idx]\n",
    "    idx = np.argsort(-np.abs(w))[:k]\n",
    "    names = [CONCEPT_NAMES[i] if i < len(CONCEPT_NAMES) else f'c{i}' for i in idx]\n",
    "    vals = w[idx]\n",
    "    return list(zip(names, vals))\n",
    "\n",
    "print(\"Top concepts for class 0:\", top_concepts_for_class(10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-sample explanation ---\n",
    "def show_image(timg):\n",
    "    inv = T.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "        std=[1/0.229, 1/0.224, 1/0.225]\n",
    "    )\n",
    "    img = inv(timg).clamp(0,1).permute(1,2,0).cpu().numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def explain_sample(idx: int, top_n: int = TOP_CONTRIB):\n",
    "    x, y = ds[idx]\n",
    "    with torch.no_grad():\n",
    "        f = backbone(x.unsqueeze(0).to(DEVICE))\n",
    "        if f.ndim > 2:\n",
    "            f = torch.flatten(f, 1)\n",
    "        c = (f.cpu() @ W_c.t()).squeeze(0)           # [C]\n",
    "        ylog = (c @ W_y.t()).cpu().numpy()           # [K]\n",
    "    pred = int(np.argmax(ylog))\n",
    "    contrib = (c.numpy() * W_y[pred].cpu().numpy())  # signed contribution per concept\n",
    "\n",
    "    print(f\"idx={idx} | GT={CLASS_NAMES[int(y)]} ({int(y)}) | Pred={CLASS_NAMES[pred]} ({pred})\")\n",
    "    show_image(x)\n",
    "    barplot_contributions(CONCEPTS_TXT if isinstance(CONCEPTS_TXT, list) else (CONCEPTS_TXT or CONCEPTS_TXT), contrib, \n",
    "                          title=f\"Top concept contributions → {CLASS_NAMES[pred]}\", top_n=top_n)\n",
    "\n",
    "# Quick demo\n",
    "for i in [0, 1, 2]:\n",
    "    explain_sample(i, top_n=TOP_CONTRIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167436f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: export explanations ---\n",
    "EXPORT_PATH = os.environ.get(\"EXPORT_JSONL\", \"/kayla/logs/eval_explanations.jsonl\")\n",
    "K = int(os.environ.get(\"EXPORT_TOPK\", 10))\n",
    "Path(\"/kayla/logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def topk_concepts_for_pred(contrib: np.ndarray, k: int) -> list:\n",
    "    idx = np.argsort(-np.abs(contrib))[:k]\n",
    "    names = [CONCEPT_NAMES[i] if i < len(CONCEPT_NAMES) else f'c{i}' for i in idx]\n",
    "    vals = contrib[idx].tolist()\n",
    "    return [{\"concept\": n, \"contribution\": v, \"index\": int(i)} for n, v, i in zip(names, vals, idx)]\n",
    "\n",
    "@torch.no_grad()\n",
    "def export_explanations(jsonl_path: str, num_samples: int = 50):\n",
    "    with open(jsonl_path, \"w\") as f:\n",
    "        for i in range(min(num_samples, len(ds))):\n",
    "            x, y = ds[i]\n",
    "            ftr = backbone(x.unsqueeze(0).to(DEVICE))\n",
    "            if ftr.ndim > 2:\n",
    "                ftr = torch.flatten(ftr, 1)\n",
    "            c = (ftr.cpu() @ W_c.t()).squeeze(0).numpy()\n",
    "            ylog = (c @ W_y.t().cpu().numpy())\n",
    "            pred = int(np.argmax(ylog))\n",
    "            contrib = (c * W_y[pred].cpu().numpy())\n",
    "            topk = topk_concepts_for_pred(contrib, K)\n",
    "            rec = {\n",
    "                \"index\": i,\n",
    "                \"gt\": int(y),\n",
    "                \"gt_name\": CLASS_NAMES[int(y)],\n",
    "                \"pred\": pred,\n",
    "                \"pred_name\": CLASS_NAMES[pred],\n",
    "                \"top_concepts\": topk,\n",
    "            }\n",
    "            f.write(json.dumps(rec) + \"\\n\")\n",
    "    print(f\"Wrote {jsonl_path}\")\n",
    "\n",
    "# To run:\n",
    "# export_explanations(EXPORT_PATH, num_samples=100)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
